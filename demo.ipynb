{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e73b1ddd",
   "metadata": {},
   "source": [
    "# Case de Entrevista – Cientista de Dados (Welhome)\n",
    "\n",
    "**Autor:** Gabriel Fabiano de Souza\n",
    "\n",
    "**Data:** 30/09/2025\n",
    "\n",
    "Para updates e novidades: https://github.com/edr0k/chatbot-welhome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f879829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas e .env carregado. CACHE ATIVADO.\n",
      "Modelo LLM (Groq Llama 3) e Embeddings (Google Generative AI) inicializados.\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade langchain langchain-groq langchain-huggingface faiss-cpu python-dotenv sentence-transformers pydantic\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Importações para Groq (LLM) e Google (Embeddings)\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# Importações do LangChain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Importações para parsing estruturado e validação\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "# Importação para cache para não gastar tokens desnecessários\n",
    "import langchain\n",
    "from langchain.cache import SQLiteCache\n",
    "\n",
    "# Carrega a GROQ_API_KEY e a GOOGLE_API_KEY do seu arquivo .env\n",
    "load_dotenv()\n",
    "# Isso criará um arquivo .langchain.db na sua pasta para armazenar as respostas.\n",
    "langchain.llm_cache = SQLiteCache(database_path=\".langchain.db\")\n",
    "# Limpa o cache, caso queira respostas completamente novas\n",
    "# if langchain.llm_cache:\n",
    "#     langchain.llm_cache.clear()\n",
    "\n",
    "print(\"Bibliotecas importadas e .env carregado. CACHE ATIVADO.\")\n",
    "\n",
    "\n",
    "# Inicializa o LLM da Groq\n",
    "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\", temperature=0.7)\n",
    "\n",
    "# Inicializa o modelo de embeddings da Google Generative AI\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "print(\"Modelo LLM (Groq Llama 3) e Embeddings (Google Generative AI) inicializados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e69a2a5",
   "metadata": {},
   "source": [
    "## PARTE 1 - CHATBOT ASSISTENTE COM MEMÓRIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41f681c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot com memória configurado.\n"
     ]
    }
   ],
   "source": [
    "# Prompt que define o comportamento do assistente\n",
    "prompt_chat = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é um assistente virtual da Welhome, amigável e eficiente. Seu objetivo é fazer uma qualificação inicial do lead, fazendo as perguntas necessárias uma de cada vez. Seja cordial e natural.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# Chain de conversação com a sintaxe do LangChain\n",
    "runnable = prompt_chat | llm\n",
    "\n",
    "# Armazenamento em memória para o histórico das conversas\n",
    "# Cada lead terá seu histórico separado por um 'session_id'\n",
    "store = {}\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Wrapper que adiciona a gestão de memória à nossa chain\n",
    "conversation_with_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "print(\"Chatbot com memória configurado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007218ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Simulação da Conversa ---\n",
      "Assistente: Olá! É um prazer conhecer você! A Welhome é uma empresa que oferece serviços de gestão de propriedades e soluções para proprietários e inquilinos. Nós podemos ajudar com tudo, desde a gestão de aluguéis até a manutenção de propriedades.\n",
      "\n",
      "Antes de começarmos, gostaria de saber: qual é o seu interesse principal na Welhome? Você é um proprietário de propriedade que busca gerenciar seus imóveis de forma eficiente, ou você está procurando por uma solução para encontrar um lugar para morar?\n",
      "---\n",
      "Assistente: Entendo perfeitamente! Gerenciar várias propriedades pode ser um desafio, especialmente quando se está sozinho. A Welhome pode ajudar a aliviar essa carga, oferecendo serviços de gestão de propriedades personalizados para atender às suas necessidades.\n",
      "\n",
      "Você mencionou que tem 3 imóveis em São Paulo e 1 no Rio de Janeiro. Isso significa que você precisa lidar com diferentes mercados e regulamentações em cada cidade. Nossa equipe tem experiência em gerenciar propriedades em diferentes regiões do Brasil.\n",
      "\n",
      "Para melhor entender como podemos ajudar, gostaria de saber: quais são os principais desafios que você enfrenta ao gerenciar seus imóveis? É a busca por inquilinos, a manutenção das propriedades, a gestão de aluguéis ou algo mais?\n",
      "---\n",
      "Assistente: Entendo melhor agora! Gerenciar propriedades pode ser um desafio, especialmente quando se está lidando com muitas informações e detalhes. Uma planilha pode ser um bom começo, mas é fácil se perder em meio a tantos dados e tarefas.\n",
      "\n",
      "A Welhome oferece soluções de gestão de propriedades que podem ajudar a organizá-lo e a ter mais controle sobre seus imóveis. Nossa plataforma de gestão de propriedades é projetada para ser fácil de usar e pode ajudar a automatizar muitas tarefas, como a gestão de aluguéis, a manutenção de propriedades e a comunicação com inquilinos.\n",
      "\n",
      "Além disso, nossa equipe de especialistas em gestão de propriedades pode ajudar a fornecer orientação e suporte para que você possa tomar decisões informadas sobre seus imóveis.\n",
      "\n",
      "Para entender melhor como podemos ajudar, gostaria de saber: você está procurando por uma solução que o ajude a gerenciar todos os aspectos de seus imóveis, ou há algo específico que você gostaria de melhorar, como a gestão de aluguéis ou a manutenção de propriedades?\n",
      "---\n",
      "--- Simulação Concluída ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Iniciando Simulação da Conversa ---\")\n",
    "session_id = \"demo_001\"\n",
    "config = {\"configurable\": {\"session_id\": session_id}}\n",
    "\n",
    "# Simula uma conversa completa para coletar os dados\n",
    "print(\"Assistente:\", conversation_with_history.invoke({\"input\": \"Olá, eu gostaria de saber mais sobre os serviços da Welhome.\"}, config=config).content)\n",
    "print(\"---\")\n",
    "print(\"Assistente:\", conversation_with_history.invoke({\"input\": \"Eu tenho 3 imóveis em São Paulo e 1 no Rio de Janeiro. Administro tudo sozinho, mas já estou cansado disso.\"}, config=config).content)\n",
    "print(\"---\")\n",
    "print(\"Assistente:\", conversation_with_history.invoke({\"input\": \"Minha experiência é bem básica, só anoto as coisas numa planilha e sempre me perco.\"}, config=config).content)\n",
    "print(\"---\")\n",
    "print(\"--- Simulação Concluída ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e48cbacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Análise Avançada do Lead ---\n",
      "Pontuação do Lead: 8/10\n",
      "Intenção Detectada: Pronto para contratar\n",
      "Justificativa: O lead tem 4 imóveis e está cansado de administrá-los sozinho, com experiência básica em gerenciamento de propriedades.\n"
     ]
    }
   ],
   "source": [
    "# Pega o histórico da conversa que acabamos de simular\n",
    "historico_conversa = get_session_history(session_id).messages\n",
    "\n",
    "# --- Definição das Estruturas de Saída com Pydantic ---\n",
    "# Isso garante que a saída do LLM será sempre um JSON estruturado e validado.\n",
    "class LeadAnalysis(BaseModel):\n",
    "    score: int = Field(description=\"Uma pontuação de 1 a 10 indicando o potencial do lead, onde 10 é muito alto.\")\n",
    "    intent: str = Field(description=\"A intenção do lead, classificada como 'Pronto para contratar', 'Buscando informações' ou 'Apenas curioso'.\")\n",
    "    reasoning: str = Field(description=\"Uma breve explicação em uma frase sobre o porquê da pontuação e da intenção atribuídas.\")\n",
    "\n",
    "# --- Criação do Parser e do Prompt ---\n",
    "output_parser = PydanticOutputParser(pydantic_object=LeadAnalysis)\n",
    "\n",
    "prompt_analise = ChatPromptTemplate.from_template(\"\"\"\n",
    "Analise o histórico de conversa com um potencial cliente da Welhome.\n",
    "Com base na conversa, atribua uma pontuação de potencial e classifique a intenção do lead.\n",
    "Considere fatores como número de imóveis, os problemas e dificuldades mencionados (ex: 'cansado de administrar'), e nível de experiência.\n",
    "Um lead com mais imóveis e mais \"dores\" tem um score maior.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Histórico da Conversa:\n",
    "{historico}\n",
    "\"\"\")\n",
    "\n",
    "# --- Criação e Execução da Chain de Análise ---\n",
    "analysis_chain = prompt_analise | llm | output_parser\n",
    "lead_analysis_result = analysis_chain.invoke({\n",
    "    \"historico\": historico_conversa,\n",
    "    \"format_instructions\": output_parser.get_format_instructions()\n",
    "})\n",
    "\n",
    "print(\"--- Análise Avançada do Lead ---\")\n",
    "print(f\"Pontuação do Lead: {lead_analysis_result.score}/10\")\n",
    "print(f\"Intenção Detectada: {lead_analysis_result.intent}\")\n",
    "print(f\"Justificativa: {lead_analysis_result.reasoning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75100933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resumo Estruturado para o Vendedor ---\n",
      "Nome: Não informado\n",
      "Quantidade imoveis: 4\n",
      "Localizacao: São Paulo e Rio de Janeiro\n",
      "Experiencia previa: Básica, utiliza planilha para gerenciar imóveis\n",
      "Lead score: 8\n",
      "Intencao: Pronto para contratar\n",
      "Resumo qualitativo: O lead tem 4 imóveis, 3 em São Paulo e 1 no Rio de Janeiro, e está procurando por uma solução para gerenciar seus imóveis de forma mais eficiente. Ele tem experiência básica em gestão de propriedades e está pronto para contratar uma empresa para ajudá-lo.\n"
     ]
    }
   ],
   "source": [
    "class LeadSummary(BaseModel):\n",
    "    nome: str = Field(description=\"Nome do lead, se mencionado. Caso contrário, 'Não informado'.\")\n",
    "    quantidade_imoveis: int = Field(description=\"Número de imóveis que o lead possui.\")\n",
    "    localizacao: str = Field(description=\"Cidade ou região dos imóveis.\")\n",
    "    experiencia_previa: str = Field(description=\"Descrição da experiência do lead com administração de imóveis.\")\n",
    "    lead_score: int = Field(description=\"A pontuação de potencial do lead (1-10).\")\n",
    "    intencao: str = Field(description=\"A intenção classificada do lead.\")\n",
    "    resumo_qualitativo: str = Field(description=\"Um resumo de 2-3 frases sobre a principal necessidade e situação do lead.\")\n",
    "\n",
    "summary_parser = PydanticOutputParser(pydantic_object=LeadSummary)\n",
    "\n",
    "prompt_resumo_final = ChatPromptTemplate.from_template(\"\"\"\n",
    "Extraia as informações do histórico de conversa e da análise do lead para criar um resumo estruturado para o vendedor.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Histórico da Conversa:\n",
    "{historico}\n",
    "\n",
    "Análise de Score e Intenção:\n",
    "- Score: {score}\n",
    "- Intenção: {intencao}\n",
    "\"\"\")\n",
    "\n",
    "summary_chain = prompt_resumo_final | llm | summary_parser\n",
    "\n",
    "final_summary = summary_chain.invoke({\n",
    "    \"historico\": historico_conversa,\n",
    "    \"score\": lead_analysis_result.score,\n",
    "    \"intencao\": lead_analysis_result.intent,\n",
    "    \"format_instructions\": summary_parser.get_format_instructions()\n",
    "})\n",
    "\n",
    "print(\"--- Resumo Estruturado para o Vendedor ---\")\n",
    "for item, value in final_summary.model_dump().items():\n",
    "    print(f\"{item.replace('_', ' ').capitalize()}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bae69c",
   "metadata": {},
   "source": [
    "## PARTE 2 - SISTEMA DE RAG COM FAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f6f7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAQ da Welhome\n",
    "faq_welhome = \"\"\"\n",
    "Pergunta: Como a Welhome garante que o aluguel será pago em dia?\n",
    "Resposta: A Welhome oferece a garantia de aluguel em dia. Mesmo que o inquilino atrase, nós garantimos o repasse do valor para o proprietário na data combinada, sem custos adicionais.\n",
    "\n",
    "Pergunta: Quem é responsável pela manutenção do imóvel?\n",
    "Resposta: Reparos estruturais são de responsabilidade do proprietário. Pequenas manutenções do dia a dia, como troca de lâmpadas, são do inquilino. Nossa plataforma ajuda a intermediar e orçar serviços de manutenção quando necessário.\n",
    "\n",
    "Pergunta: Qual é o custo da taxa de administração da Welhome?\n",
    "Resposta: Nossa taxa de administração é de 8% sobre o valor do aluguel. Essa taxa cobre a gestão completa do seu imóvel, incluindo divulgação, gestão de contratos, repasse garantido e suporte.\n",
    "\n",
    "Pergunta: Como funciona a vistoria do imóvel?\n",
    "Resposta: Realizamos uma vistoria profissional completa, com fotos e vídeos, antes da entrada do inquilino e após a sua saída. Isso garante que o imóvel seja devolvido nas mesmas condições em que foi entregue.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db5b801f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup do RAG concluído.\n"
     ]
    }
   ],
   "source": [
    "# Dividir e Vetorizar\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = text_splitter.create_documents([faq_welhome])\n",
    "vector_store = FAISS.from_documents(docs, embeddings)\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Prompt e Chain de RAG\n",
    "prompt_rag_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "Responda a pergunta do usuário de forma natural com base apenas no contexto fornecido:\n",
    "Contexto:\n",
    "{context}\n",
    "\n",
    "Pergunta: {input}\n",
    "\"\"\")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt_rag_template)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "print(\"Setup do RAG concluído.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e630c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PERGUNTA: Quanto vocês cobram pelo serviço?\n",
      "RESPOSTA: Nossa taxa de administração é de 8% sobre o valor do aluguel. Essa taxa cobre a gestão completa do seu imóvel, incluindo divulgação, gestão de contratos, repasse garantido e suporte. Não há outros custos adicionais para o proprietário, exceto pelos reparos estruturais, que são de responsabilidade do proprietário.\n",
      "\n",
      "PERGUNTA: Eu terei contato direto com o inquilino durante todo o processo?\n",
      "RESPOSTA: Não, como proprietário, você não terá contato direto com o inquilino. A Welhome atua como intermediária, lidando com todas as questões relacionadas ao aluguel, incluindo a comunicação com o inquilino. Isso inclui a gestão de contratos, vistorias, manutenção e garantia de pagamento do aluguel. Nossa equipe está sempre disponível para ajudar e manter você informado sobre o status do seu imóvel.\n"
     ]
    }
   ],
   "source": [
    "# Pergunta teste para o RAG que está no FAQ\n",
    "pergunta_teste_rag = \"Quanto vocês cobram pelo serviço?\"\n",
    "resposta_rag = rag_chain.invoke({\"input\": pergunta_teste_rag})\n",
    "\n",
    "print(f\"\\nPERGUNTA: {pergunta_teste_rag}\")\n",
    "print(f\"RESPOSTA: {resposta_rag['answer']}\")\n",
    "\n",
    "# Pergunta teste para o RAG que não está no FAQ\n",
    "pergunta_teste_rag = \"Eu terei contato direto com o inquilino durante todo o processo?\"\n",
    "resposta_rag = rag_chain.invoke({\"input\": pergunta_teste_rag})\n",
    "\n",
    "print(f\"\\nPERGUNTA: {pergunta_teste_rag}\")\n",
    "print(f\"RESPOSTA: {resposta_rag['answer']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762376eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
