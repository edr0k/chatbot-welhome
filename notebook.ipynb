{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e73b1ddd",
   "metadata": {},
   "source": [
    "# Case de Entrevista – Cientista de Dados (Welhome)\n",
    "\n",
    "**Autor:** Gabriel Fabiano de Souza\n",
    "\n",
    "**Data:** 30/09/2025\n",
    "\n",
    "Para updates e novidades: https://github.com/edr0k/chatbot-welhome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f879829",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas e .env carregado.\n",
      "Modelo LLM (Groq Llama 3) e Embeddings (Google Generative AI) inicializados.\n"
     ]
    }
   ],
   "source": [
    "# !pip install --upgrade langchain langchain-groq langchain-huggingface faiss-cpu python-dotenv sentence-transformers pydantic\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Importações para Groq (LLM) e Google (Embeddings)\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "# Importações do LangChain\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "# Importações para parsing estruturado e validação\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "\n",
    "# Carrega a GROQ_API_KEY e a GOOGLE_API_KEY do seu arquivo .env\n",
    "load_dotenv()\n",
    "print(\"Bibliotecas importadas e .env carregado.\")\n",
    "\n",
    "# Inicializa o LLM da Groq\n",
    "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\", temperature=0.7)\n",
    "\n",
    "# Inicializa o modelo de embeddings da Google Generative AI\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "\n",
    "print(\"Modelo LLM (Groq Llama 3) e Embeddings (Google Generative AI) inicializados.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e69a2a5",
   "metadata": {},
   "source": [
    "## PARTE 1 - CHATBOT ASSISTENTE COM MEMÓRIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41f681c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot com memória configurado.\n"
     ]
    }
   ],
   "source": [
    "# Prompt que define o comportamento do assistente\n",
    "prompt_chat = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Você é um assistente virtual da Welhome, amigável e eficiente. Seu objetivo é fazer uma qualificação inicial do lead, fazendo as perguntas necessárias uma de cada vez. Seja cordial e natural.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])\n",
    "\n",
    "# Chain de conversação com a sintaxe moderna do LangChain (LCEL)\n",
    "runnable = prompt_chat | llm\n",
    "\n",
    "# Armazenamento em memória para o histórico das conversas\n",
    "# Cada lead terá seu histórico separado por um 'session_id'\n",
    "store = {}\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Wrapper que adiciona a gestão de memória à nossa chain\n",
    "conversation_with_history = RunnableWithMessageHistory(\n",
    "    runnable,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    ")\n",
    "\n",
    "print(\"Chatbot com memória configurado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "007218ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando Simulação da Conversa ---\n",
      "Assistente: Olá! É um prazer conversar com você! A Welhome é uma empresa especializada em serviços de gestão de propriedades e soluções para proprietários e inquilinos. Nossa equipe está aqui para ajudar a tornar a experiência de morar ou alugar uma propriedade mais fácil e agradável.\n",
      "\n",
      "Antes de começarmos a conversar sobre os serviços específicos, gostaria de saber: você é proprietário de uma propriedade ou está procurando por uma solução para alugar um imóvel?\n",
      "Assistente: Entendo perfeitamente! Administrar múltiplas propriedades pode ser um desafio, especialmente em uma cidade grande como São Paulo. A Welhome pode ajudar a aliviar essa carga e fornecer soluções personalizadas para gerenciar seus imóveis de forma eficiente.\n",
      "\n",
      "Você mencionou que está cansado de administrar tudo sozinho, então posso imaginar que você está procurando por uma solução que possa ajudar a reduzir o estresse e o tempo gasto com a gestão dos imóveis.\n",
      "\n",
      "Pode me dizer, quais são os principais desafios que você enfrenta ao administrar seus imóveis? É a busca por inquilinos, a manutenção do imóvel, a cobrança de alugueis ou algo mais?\n",
      "Assistente: Entendo melhor agora! É comum que os proprietários de imóveis tenham dificuldade em gerenciar todas as informações e tarefas relacionadas à propriedade, especialmente quando se tem múltiplos imóveis.\n",
      "\n",
      "Uma planilha pode ser um bom começo, mas é fácil se perder na quantidade de informações e prazos. É como se você estivesse tentando gerenciar uma pequena empresa, mas sem as ferramentas e recursos necessários.\n",
      "\n",
      "A Welhome tem soluções que podem ajudar a automatizar e organizar a gestão dos seus imóveis, tornando mais fácil para você manter tudo sob controle. Nossa plataforma pode ajudar a gerenciar alugueis, pagamentos, manutenção, e até mesmo a encontrar novos inquilinos.\n",
      "\n",
      "Gostaria de saber, você já teve problemas com inquilinos que não pagam aluguel no prazo ou que danificam o imóvel? Ou você tem uma boa relação com seus inquilinos atuais?\n",
      "--- Simulação Concluída ---\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Iniciando Simulação da Conversa ---\")\n",
    "session_id = \"lead_teste_001\"\n",
    "config = {\"configurable\": {\"session_id\": session_id}}\n",
    "\n",
    "# Simula uma conversa completa para coletar os dados\n",
    "print(\"Assistente:\", conversation_with_history.invoke({\"input\": \"Olá, eu gostaria de saber mais sobre os serviços da Welhome.\"}, config=config).content)\n",
    "print(\"Assistente:\", conversation_with_history.invoke({\"input\": \"Claro! Eu tenho 3 imóveis em São Paulo e estou cansado de administrar tudo sozinho.\"}, config=config).content)\n",
    "print(\"Assistente:\", conversation_with_history.invoke({\"input\": \"Minha experiência é bem básica, só anoto as coisas numa planilha e sempre me perco.\"}, config=config).content)\n",
    "print(\"--- Simulação Concluída ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e48cbacf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Análise Avançada do Lead ---\n",
      "Pontuação do Lead: 8/10\n",
      "Intenção Detectada: Pronto para contratar\n",
      "Justificativa: O lead tem 3 imóveis e está procurando por uma solução para aliviar a carga de trabalho e reduzir o estresse, indicando um alto potencial de contratação.\n"
     ]
    }
   ],
   "source": [
    "# Pega o histórico da conversa que acabamos de simular\n",
    "historico_conversa = get_session_history(session_id).messages\n",
    "\n",
    "# --- Definição das Estruturas de Saída com Pydantic ---\n",
    "# Isso garante que a saída do LLM será sempre um JSON estruturado e validado.\n",
    "class LeadAnalysis(BaseModel):\n",
    "    score: int = Field(description=\"Uma pontuação de 1 a 10 indicando o potencial do lead, onde 10 é muito alto.\")\n",
    "    intent: str = Field(description=\"A intenção do lead, classificada como 'Pronto para contratar', 'Buscando informações' ou 'Apenas curioso'.\")\n",
    "    reasoning: str = Field(description=\"Uma breve explicação em uma frase sobre o porquê da pontuação e da intenção atribuídas.\")\n",
    "\n",
    "# --- Criação do Parser e do Prompt ---\n",
    "output_parser = PydanticOutputParser(pydantic_object=LeadAnalysis)\n",
    "\n",
    "prompt_analise = ChatPromptTemplate.from_template(\"\"\"\n",
    "Analise o histórico de conversa com um potencial cliente da Welhome.\n",
    "Com base na conversa, atribua uma pontuação de potencial e classifique a intenção do lead.\n",
    "Considere fatores como número de imóveis, \"dores\" mencionadas (ex: 'cansado de administrar') e nível de experiência.\n",
    "Um lead com mais imóveis e mais \"dores\" tem um score maior.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Histórico da Conversa:\n",
    "{historico}\n",
    "\"\"\")\n",
    "\n",
    "# --- Criação e Execução da Chain de Análise ---\n",
    "analysis_chain = prompt_analise | llm | output_parser\n",
    "lead_analysis_result = analysis_chain.invoke({\n",
    "    \"historico\": historico_conversa,\n",
    "    \"format_instructions\": output_parser.get_format_instructions()\n",
    "})\n",
    "\n",
    "print(\"--- Análise Avançada do Lead ---\")\n",
    "print(f\"Pontuação do Lead: {lead_analysis_result.score}/10\")\n",
    "print(f\"Intenção Detectada: {lead_analysis_result.intent}\")\n",
    "print(f\"Justificativa: {lead_analysis_result.reasoning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "75100933",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Resumo Estruturado para o Vendedor ---\n",
      "Nome: Não informado\n",
      "Quantidade imoveis: 3\n",
      "Localizacao: São Paulo\n",
      "Experiencia previa: Básica, utilizando planilha para anotar informações\n",
      "Lead score: 8\n",
      "Intencao: Pronto para contratar\n",
      "Resumo qualitativo: O lead possui 3 imóveis em São Paulo e está procurando por uma solução para gerenciar seus imóveis de forma eficiente, pois está cansado de administrar tudo sozinho. Ele tem experiência básica em administração de imóveis e está pronto para contratar serviços de gestão de propriedades.\n"
     ]
    }
   ],
   "source": [
    "class LeadSummary(BaseModel):\n",
    "    nome: str = Field(description=\"Nome do lead, se mencionado. Caso contrário, 'Não informado'.\")\n",
    "    quantidade_imoveis: int = Field(description=\"Número de imóveis que o lead possui.\")\n",
    "    localizacao: str = Field(description=\"Cidade ou região dos imóveis.\")\n",
    "    experiencia_previa: str = Field(description=\"Descrição da experiência do lead com administração de imóveis.\")\n",
    "    lead_score: int = Field(description=\"A pontuação de potencial do lead (1-10).\")\n",
    "    intencao: str = Field(description=\"A intenção classificada do lead.\")\n",
    "    resumo_qualitativo: str = Field(description=\"Um resumo de 2-3 frases sobre a principal necessidade e situação do lead.\")\n",
    "\n",
    "summary_parser = PydanticOutputParser(pydantic_object=LeadSummary)\n",
    "\n",
    "prompt_resumo_final = ChatPromptTemplate.from_template(\"\"\"\n",
    "Extraia as informações do histórico de conversa e da análise do lead para criar um resumo estruturado para o vendedor.\n",
    "\n",
    "{format_instructions}\n",
    "\n",
    "Histórico da Conversa:\n",
    "{historico}\n",
    "\n",
    "Análise de Score e Intenção:\n",
    "- Score: {score}\n",
    "- Intenção: {intencao}\n",
    "\"\"\")\n",
    "\n",
    "summary_chain = prompt_resumo_final | llm | summary_parser\n",
    "\n",
    "final_summary = summary_chain.invoke({\n",
    "    \"historico\": historico_conversa,\n",
    "    \"score\": lead_analysis_result.score,\n",
    "    \"intencao\": lead_analysis_result.intent,\n",
    "    \"format_instructions\": summary_parser.get_format_instructions()\n",
    "})\n",
    "\n",
    "print(\"--- Resumo Estruturado para o Vendedor ---\")\n",
    "for item, value in final_summary.model_dump().items():\n",
    "    print(f\"{item.replace('_', ' ').capitalize()}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29bae69c",
   "metadata": {},
   "source": [
    "## PARTE 2 - SISTEMA DE RAG COM FAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6f7ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FAQ da Welhome\n",
    "faq_welhome = \"\"\"\n",
    "Pergunta: Como a Welhome garante que o aluguel será pago em dia?\n",
    "Resposta: A Welhome oferece a garantia de aluguel em dia. Mesmo que o inquilino atrase, nós garantimos o repasse do valor para o proprietário na data combinada, sem custos adicionais.\n",
    "\n",
    "Pergunta: Quem é responsável pela manutenção do imóvel?\n",
    "Resposta: Reparos estruturais são de responsabilidade do proprietário. Pequenas manutenções do dia a dia, como troca de lâmpadas, são do inquilino. Nossa plataforma ajuda a intermediar e orçar serviços de manutenção quando necessário.\n",
    "\n",
    "Pergunta: Qual é o custo da taxa de administração da Welhome?\n",
    "Resposta: Nossa taxa de administração é de 8% sobre o valor do aluguel. Essa taxa cobre a gestão completa do seu imóvel, incluindo divulgação, gestão de contratos, repasse garantido e suporte.\n",
    "\n",
    "Pergunta: Como funciona a vistoria do imóvel?\n",
    "Resposta: Realizamos uma vistoria profissional completa, com fotos e vídeos, antes da entrada do inquilino e após a sua saída. Isso garante que o imóvel seja devolvido nas mesmas condições em que foi entregue.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5b801f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup do RAG concluído.\n"
     ]
    }
   ],
   "source": [
    "# Dividir e Vetorizar\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = text_splitter.create_documents([faq_welhome])\n",
    "vector_store = FAISS.from_documents(docs, embeddings)\n",
    "retriever = vector_store.as_retriever()\n",
    "\n",
    "# Prompt e Chain de RAG\n",
    "prompt_rag_template = ChatPromptTemplate.from_template(\"\"\"\n",
    "Responda a pergunta do usuário de forma natural com base apenas no contexto fornecido:\n",
    "Contexto:\n",
    "{context}\n",
    "\n",
    "Pergunta: {input}\n",
    "\"\"\")\n",
    "\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt_rag_template)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)\n",
    "\n",
    "print(\"Setup do RAG concluído.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e630c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PERGUNTA: Quanto vocês cobram pelo serviço?\n",
      "RESPOSTA: Nossa taxa de administração é de 8% sobre o valor do aluguel. Essa taxa cobre a gestão completa do seu imóvel, incluindo divulgação, gestão de contratos, repasse garantido e suporte. Não há outros custos adicionais além disso.\n"
     ]
    }
   ],
   "source": [
    "pergunta_teste_rag = \"Quanto vocês cobram pelo serviço?\"\n",
    "resposta_rag = rag_chain.invoke({\"input\": pergunta_teste_rag})\n",
    "\n",
    "print(f\"\\nPERGUNTA: {pergunta_teste_rag}\")\n",
    "print(f\"RESPOSTA: {resposta_rag['answer']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9252638b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6fdbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
